# プロンプト技法＋プロンプトテンプレート
## 前提として覚えておいた方がよさそうな単語
### LLM(Large Language Mode)
大量のテキストを学習し、「次に来る単語を予測して文章を生成するAIモデル」。  
ChatGPT、Claude、Geminiなどの“生成AIの本体”のこと。  
文の理解・生成・要約・推論などを幅広くこなす。  

### Transformer
現在のLLMの基盤になっているニューラルネットワークの構造（アーキテクチャ）。  
長い文章でも文脈を広く見ることができる設計が特徴。  
GPTシリーズはすべてTransformerベース。  

### Attention(Self-Attention)
文章内の「どの単語が重要か」に重みをつけて処理する仕組み。  
Transformerの中心技術で、文脈理解の精度を飛躍的に高めた。  
「役割指定」「例示」「文体指定」などが効く理由も、このAttentionにある。  

## プロンプトが回答になるまでの流れ

| ステップ | 使われる技術 | 説明 |
|----------|--------------|---------------|
| **1. プロンプトを受け取る** | **LLM（AIの本体）** | あなたの指示文を読み取り、「何について答えるか」を理解し始める。 |
| **2. 全体を読み解く** | **Transformer（AIの頭の構造）** | 文全体を一度に俯瞰して読み取り、話の流れや意味をつかむ。 |
| **3. 重要箇所に注目する** | **Attention（どこに注目すべきかを決める仕組み）** | 指示・役割・制約など、特に大事な部分に注意を集中させる。 |
| **4. 回答を組み立てる** | **LLM（生成能力）** | 学習してきた知識と文パターンを使って、自然で的確な回答を生成する。 |

**[まとめ]**  
LLM がプロンプトを受け取り、Transformer という頭脳構造で文全体を理解し、  
Attention が“どこが重要か”に集中して、その結果をもとに回答を作る。

## プロンプトの基本的な構成要素

| 構成要素                                  | 役割（何のために存在する？）              | 内容（含めるべき情報）                                   | 例                                 |
| ------------------------------------- | --------------------------- | --------------------------------------------- | --------------------------------- |
| **指示（Instruction）**                   | モデルに「何をしてほしいか」を具体的に伝える中心部分。 | ・タスク内容<br>・目的とゴール<br>・曖昧さを排除した行動指示            | 「この記事を300文字以内で要約してください。」          |
| **コンテキスト（Context）**                   | モデルが誤解しないよう、背景や前提情報を与える。    | ・対象の説明<br>・背景知識<br>・前提条件<br>・役割付与（Role）       | 「あなたはITコンサルタントです。以下は社内向けの説明資料です。」 |
| **出力指示（Format / Output Constraints）** | 出力の形を制御して、期待通りのフォーマットを得る。   | ・形式（箇条書き、表、JSON など）<br>・文字数制限<br>・禁止事項<br>・文体 | 「箇条書きで3点にまとめてください。」               |

### ポイント
以下の3つを押さえると、プロンプトの成功率が劇的に上がる。  

- 指示 = 何をしてほしいか（タスク定義）
- コンテキスト = なぜ/どういう背景で実行するのか（誤解防止）
- 出力指示 = どう出してほしいか（形式の指定）


## プロンプトの一般的なコツ × 技術的根拠（論文・理論）
| コツ | 指示例 | 技術的な根拠（論文・理論） | 補足（なぜ効くか） |
| --- | --- | --- | --- |
| **指示を具体的にする** | 数値リストを折れ線グラフ化し、解説を2行以内にまとめてください。 | ・**GPT-3論文（Few-Shot Learners, 2020）**「明確なタスク定義で性能が向上」・**In-Context Learning（多くのNLP論文）** | Transformer は曖昧な指示があると “もっともらしい出力” を生成するため、具体的にするほど誤差が減る。 |
| **役割を与える（Role Prompting）** | あなたは言語学者として回答してください。 | ・**RLHF論文（Ouyang et al., 2022）**人間フィードバックで「指示追従性」が強化・**GPT-3論文：文体模倣能力** | Role を与えると Attention が「専門家文体のパターン」に強く寄る。 |
| **例を提示する（Few-shot）** | 以下のサンプルのように書いてください。 | ・**GPT-3論文（Few-Shot Learners, 2020）**・**In-context learning の正体（2022〜）** | LLMは **例示パターンを模倣する能力** が強いため、例を与えると形式の安定性が向上する。 |
| **制約や禁止表現を設ける** | ・200文字以内で・ポジティブ表現のみ | ・**RLHF（指示遵守モデル）**・**Transformer の確率最適化理論** | 曖昧指示は“暴走”の原因。制約を指定すると探索空間が狭まり精度向上。 |
| **ステップを段階的に指示する（Step-by-step）** | まずAを要約、次にBを整理… | ・**Chain-of-Thought（CoT）論文（Google, 2022）**・**Zero-shot CoT（2022）** | 推論を段階的に行わせると、Attention が流れを追いやすくなるため論理精度が向上。 |
| **自己チェックを促す（Self-evaluation）** | 誤りがある場合は訂正し、理由を加えてください。 | ・**Self-Consistency（Google, 2022）**複数推論から整合性を選ぶ・**Reflexion（2023）**：自己修正型LLM | 「自己評価 → 自己修正」は研究でも精度向上が確認されている。 |
| **文体・トーンを指定する** | ・ビジネス文書で・カジュアル調で | ・**GPT-3論文：文体模倣能力**・**スタイル変換研究（Style Transfer）** | LLMは大量の文体データを学習しており、文体指定は Attention の重みを変える効果がある。 |


## 1. Zero-shot Prompting
### 概要(Zero-shot Prompting)
例示なしでタスクを実行させるプロンプト。指示だけで目的を伝える。  
例を与えずに、明確な指示だけでタスクを実行させる。

### こういうシーンにおすすめ(Zero-shot Prompting)
- 明確な出力形式がある
- 一般的な知識タスク
- 回答に創造性を求めない時

### 推奨用途(Zero-shot Prompting)
- 要約
- コードレビュー
- 文書変換（敬語→砕けた文など）

### テンプレート(Zero-shot Prompting)

```markdown
あなたは {役割} です。
以下のタスクを実行してください。

# タスク
{やってほしい内容}

# 制約条件
・曖昧な推測をしない
・前提を補わない
・論理的に一貫した出力を生成する

# 出力形式
{出力形式（箇条書き・表・Markdown・JSONなど）}
```

## 2. Few-shot Prompting
### 概要(Few-shot Prompting)
入力例（Input→Outputのサンプル）を提示してフォーマットや意図を学習させる。  
例示（Input→Output）を与えて、形式やスタイルを模倣させる。  

### こういうシーンにおすすめ(Few-shot Prompting)
- 形式が複雑な出力
- 文体やトーンを模倣させたい
- 誤解が起きやすいタスク

### 推奨用途(Few-shot Prompting)
- Markdown資料生成
- YouTube台本
- サムネイル文言生成
- コーディングスタイルの統一

### テンプレート(Few-shot Prompting)

```markdown
あなたは {役割} です。
以下に、入力とそれに対応する出力例を示します。

【例1】
入力：
{input_sample1}
出力：
{output_sample1}

【例2】
入力：
{input_sample2}
出力：
{output_sample2}

--- ここから本番 ---

入力：
{input}

上記の例と同じスタイル・形式で出力してください。
```

## 3. Chain-of-Thought（CoT）
### 概要(Chain-of-Thought（CoT）)
推論を段階的に説明させて、正確性を上げる。

### こういうシーンにおすすめ(Chain-of-Thought（CoT）)
- 数学、論理、推論系タスク
- 計算ミスが多いとき
- 推論を丁寧にさせたい時

### 推奨用途(Chain-of-Thought（CoT）)
- ロジックの整理
- 仕様分析
- 設計レビュー
- バグ原因解析

### テンプレート(Chain-of-Thought（CoT）)

```markdown
以下の問題について、解くためのステップを順番に説明しながら回答してください。

# 問題
{question}

# 出力形式
1. 問題の整理
2. 解法の検討
3. ステップごとの推論
4. 結論
```

## 4. Zero-shot Chain-of-Thought
### 概要(Zero-shot Chain-of-Thought)
例を与えずに「Let's think step by step」などの短い指示だけでCoT推論モードへ誘導する。  
CoTを例示なしで呼び出す。「一言で推論モードへ誘導」。

### こういうシーンにおすすめ(Zero-shot Chain-of-Thought)
- CoTを使いたいが例示を作るのが面倒
- 短いプロンプトで推論精度を上げたい

### 推奨用途(Zero-shot Chain-of-Thought)
- 要件整理
- 解法検討
- 曖昧な質問への正確な回答

### テンプレート(Zero-shot Chain-of-Thought)

```markdown:
以下の問題について、ステップバイステップで考えてください。

# 問題
{question}
```

## 5. Self-Consistency
### 概要(Self-Consistency)
CoTで複数回答を生成し、その中から最も一貫した答えを選ぶことで精度向上。  
複数のCoT回答を生成し、その中で最も一貫したものを採用。  
※ChatGPT単体では「自動で複数生成」は難しいため、人間がリクエストで回す形式に最適化。

### こういうシーンにおすすめ(Self-Consistency)
- 推論にばらつきが出るタスク・複雑な計算・論理問題・不安定な答えを安定化したい

### 推奨用途(Self-Consistency)
- 設計方針の比較
- デバッグ原因の切り分け
- 難しい数学・パズル問題

### テンプレート(Self-Consistency)

```markdown
以下の問題について、3通りの異なる推論プロセスで回答してください。
その後、もっとも一貫性が高いと判断される答えを1つ選んでください。

# 問題
{question}

# 出力形式
【回答A】
ステップ：
結論：

【回答B】
ステップ：
結論：

【回答C】
ステップ：
結論：

【最終結論】
最も一貫している回答：
理由：
```

## 6. Generate Knowledge（GK）
### 概要(Generate Knowledge（GK）)
回答前に「関連知識を生成させる」ことで推論を強化する。知識強化型CoT。  
回答する前に「自分用の知識」を生成させ、推論を安定化。

### こういうシーンにおすすめ(Generate Knowledge（GK）)
- 専門知識を伴う推論・未知領域に関する判断タスク
- 曖昧な質問の精度向上

### 推奨用途(Generate Knowledge（GK）)
- 初見の技術領域の理解
- API仕様の分析
- 新規領域のリサーチ

### テンプレート(Generate Knowledge（GK）)

```markdown
以下の問題について回答する前に、関連知識を生成してください。
その知識を使って最終回答を行ってください。

# 問題
{question}

# 出力形式
1. 関連知識の生成
2. その知識を使った推論
3. 結論
```

## 7. ReAct
### 概要(ReAct)
Reasoning（推論）＋ Acting（行動）を統合。推論しながらツール（検索等）を使う。  
推論しながら、必要なアクション（検索・コード生成など）を実行する。

### こういうシーンにおすすめ(ReAct)
- RAG、外部検索が必要なタスク・回答プロセスを透明化したい時
- 外部情報依存タスク

### 推奨用途(ReAct)
- RAG連携（検索付きChat）
- 外部ツールを使ったタスク
- コード生成と実行の組み合わせ

### テンプレート(ReAct)

```markdown
以下の問題に対して、Reasoning（推論）とAction（行動）を交互に行ってください。

# タスク
{task}

# 出力形式
Reasoning: {考えたこと}
Action: {必要な行動（例：検索・計算・コード生成）}
Observation: {アクションの結果}

これを繰り返し、最終結論に到達してください。
```

## 8. Directional Stimulus Prompting
### 概要(Directional Stimulus Prompting)
曖昧なタスクに対し「方向性（Direction）」を与えることで回答を安定化する。  
曖昧なクリエイティブタスクに「方向性（Direction）」を与えて回答を安定化。  

### こういうシーンにおすすめ(Directional Stimulus Prompting)
- 抽象的なタスク（アイデア生成など）
- 回答の“方向”をコントロールしたい
- 創造性を保ちつつ軸を与えたい

### 推奨用途(Directional Stimulus Prompting)
- YouTubeのタイトル案
- コピーライティング
- デザイン案生成
- 音楽イメージ生成（あなたの用途に最適）

### テンプレート(Directional Stimulus Prompting)

```markdown
以下のタスクに対し、方向性（Direction）を与えます。
Direction を踏まえて回答してください。

# Direction（方向性）
{方向性の指示：例「ミニマル・落ち着いた・暖色トーン」}

# タスク
{task}

# 出力形式
・方向性の要約
・方向性に沿ったアイデア
・代替案
```


## 9. Multimodal CoT
### 概要(Multimodal CoT)
画像＋テキストの「マルチモーダル」入力にCoTを適用。画像理解＋推論を可能にする。  
画像＋文章を組み合わせた推論。画像理解しながらCoTで推論。  

### こういうシーンにおすすめ(Multimodal CoT)
- 画像説明＋推論・OCRの文脈理解
- 画像に基づく判断タスク（例：医療、地図、図表）

### 推奨用途(Multimodal CoT)
- 画像に基づく判断（UI、デザイン、図表など）
- OCRした文章の文脈理解
- 写真＋文章の分析タスク

### テンプレート(Multimodal CoT)

```markdown
以下の画像を解析し、内容を理解したうえで、Chain-of-Thought に基づいて回答してください。

# 画像
{画像をアップロード}

# タスク
{task}

# 出力形式
1. 画像の観察内容
2. 推論ステップ
3. 結論
```
